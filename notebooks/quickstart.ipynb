{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19f1980-cb70-49c3-b9d7-6d5a3791ef3c",
   "metadata": {},
   "source": [
    "### tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c435d854-5c33-435a-a9f4-54905fd97c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count: 23\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from typing import List, Dict\n",
    "\n",
    "def count_tiktoken_length(messages: List[Dict[str, str]], model_name: str = \"gpt-3.5-turbo\") -> int:\n",
    "    \"\"\"\n",
    "    Counts the total number of tokens in a list of messages using tiktoken.\n",
    "\n",
    "    Args:\n",
    "        messages (List[Dict[str, str]]): List of messages, where each message is a dictionary\n",
    "                                         with keys like \"role\" and \"content\".\n",
    "        model_name (str): The name of the model for which the tokenization should be done.\n",
    "                          Default is \"gpt-3.5-turbo\".\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of tokens across all messages.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the tokenizer for the specified model\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "        \n",
    "        total_tokens = 0\n",
    "        \n",
    "        for message in messages:\n",
    "            for key, value in message.items():\n",
    "                # Count tokens for each value in the message dictionary\n",
    "                total_tokens += len(encoding.encode(value))\n",
    "        \n",
    "        return total_tokens\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error in calculating token length: {e}\")\n",
    "\n",
    "# Example usage\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like today?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The weather is sunny and warm.\"}\n",
    "]\n",
    "\n",
    "token_count = count_tiktoken_length(messages)\n",
    "print(f\"Total token count: {token_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a6fd6-551e-430e-b12b-d6c7825cbeb0",
   "metadata": {},
   "source": [
    "### docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ca8a0-ba75-4e2e-97ac-5c003adf6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir,\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095154da-c930-4c24-b95d-a76f0dfd1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract pdf page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efe031-9ef7-4d70-add0-3032e3d48f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b74b40-948f-41ff-b7d6-d3480a0e49d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4de2cc71-6188-4d6e-ad2c-ea024ab5f4a3",
   "metadata": {},
   "source": [
    "### openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a543e7b-c8ea-47b6-8819-b49eaa9cd826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successfully!\n",
      "API key set successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir,\"..\"))\n",
    "\n",
    "from utils.helper import set_openai_key, test_openai_api, create_openai_client\n",
    "\n",
    "print(\"Import successfully!\")\n",
    "\n",
    "# Set openai key\n",
    "set_openai_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef57f5a-55aa-4678-9075-5b1038453fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "# Test openai api\n",
    "test_openai_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0473b3e-b1ca-4477-8568-ac7d651a47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create openai client\n",
    "client = create_openai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e732a243-b289-4696-9194-cdc11e4ab944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Ace9u6rUbil7JuJUJv9q5laSHt6TK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1733774198, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_c7ca0ebaca', usage=CompletionUsage(completion_tokens=5, prompt_tokens=12, total_tokens=17, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4609e08-42fb-4bf4-a83f-066d316c9905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
